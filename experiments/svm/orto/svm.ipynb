{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitvenvcvvenv6cf5d49a40c1440a9f0299998fa89af2",
   "display_name": "Python 3.8.5 64-bit ('venv_cv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.models.train_model import train_svm\n",
    "from src.data.dataset_loaders import OrtoDatasetLoader\n",
    "from src.features.pipelines import RawImageToFeatures\n",
    "from src.data.image_loaders import OrtoFixedSizeImageLoader\n",
    "from src.models.detectors import SliderProbDetector\n",
    "from src.data.sliders import SlidingWindow\n",
    "from src.features.descriptors import HOGDescriptor, LBPDescriptor\n",
    "from src.models.classifiers import ProbSVMModelWrapper\n",
    "from src.evaluation import validate_model, precision, recall, f1_score"
   ]
  },
  {
   "source": [
    "# Orto\n",
    "# SVM Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = '../../../models/svm/aerial_svm.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_MODEL_PATH, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BND_BOX_SIZE = (80, 80)\n",
    "\n",
    "dataset_loader = OrtoDatasetLoader(\n",
    "    image_loader=OrtoFixedSizeImageLoader(\n",
    "        bnd_box_size=BND_BOX_SIZE\n",
    "    )\n",
    ")\n",
    "\n",
    "process_pipeline = RawImageToFeatures(\n",
    "    processors=[],\n",
    "    descriptors=[\n",
    "        HOGDescriptor(\n",
    "            orientations = 9,\n",
    "            cells_per_block = (2, 2),\n",
    "            pixels_per_cell = (4, 4),\n",
    "            multichannel = True,\n",
    "            visualize = True\n",
    "        ),\n",
    "        LBPDescriptor(\n",
    "            bins = 256,\n",
    "            range = (0, 256)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "sliding_window = SlidingWindow(\n",
    "    step_size=20,\n",
    "    window_size=BND_BOX_SIZE\n",
    ")"
   ]
  },
  {
   "source": [
    "#### treshold = 0.9; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 1/5 [07:43<30:55, 463.84s/it]8\n",
      " 40%|████      | 2/5 [15:28<23:12, 464.22s/it]3\n",
      " 60%|██████    | 3/5 [23:01<15:21, 460.63s/it]57\n",
      " 80%|████████  | 4/5 [30:25<07:35, 455.59s/it]43\n",
      "100%|██████████| 5/5 [37:48<00:00, 453.75s/it]49\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "-0.5255179383527034 = -3120 / 5937.0, (3120, 1120, 3200, 1120, 3120, 1040, 3200, 1040), (3141, 1059, 3212, 1059, 3141, 1112, 3212, 1112)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d75c68fa6d42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m true_positives, false_positives, false_negatives, processed_images = validate_model(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdataset_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_folder_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../../data/raw/orto/val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/evaluation.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(dataset_loader, input_folder_filepath, images_files_types, annotations_files_types, detector, output_folder_filepath, workers, iou_threshold)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bnd_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bnd_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mtrue_positives\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mfalse_positives\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/evaluation.py\u001b[0m in \u001b[0;36mevaluate_image\u001b[0;34m(image, pred_bnd_boxes, iou_threshold)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mbest_true_matched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_box\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_bnd_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersection_over_union\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpred_max_iou\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mpred_max_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/evaluation.py\u001b[0m in \u001b[0;36mintersection_over_union\u001b[0;34m(box1, box2)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# intersection over union\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersection\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0miou\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{} = {} / {}, {}, {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: -0.5255179383527034 = -3120 / 5937.0, (3120, 1120, 3200, 1120, 3120, 1040, 3200, 1040), (3141, 1059, 3212, 1059, 3141, 1112, 3212, 1112)"
     ]
    }
   ],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.9,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t9nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "source": [
    "#### treshold = 0.95; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.95,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t95nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "source": [
    "treshold = 0.98; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.98,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t98nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}