{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitvenvcvvenv6cf5d49a40c1440a9f0299998fa89af2",
   "display_name": "Python 3.8.5 64-bit ('venv_cv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.models.train_model import train_svm\n",
    "from src.data.dataset_loaders import OrtoDatasetLoader\n",
    "from src.features.pipelines import RawImageToFeatures\n",
    "from src.data.image_loaders import OrtoFixedSizeImageLoader\n",
    "from src.models.detectors import SliderProbDetector\n",
    "from src.data.sliders import SlidingWindow\n",
    "from src.features.descriptors import HOGDescriptor, LBPDescriptor\n",
    "from src.models.classifiers import ProbSVMModelWrapper\n",
    "from src.evaluation import validate_model, precision, recall, f1_score"
   ]
  },
  {
   "source": [
    "# Orto\n",
    "# SVM Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = '../../../models/svm/aerial_svm.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_MODEL_PATH, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BND_BOX_SIZE = (80, 80)\n",
    "\n",
    "dataset_loader = OrtoDatasetLoader(\n",
    "    image_loader=OrtoFixedSizeImageLoader(\n",
    "        bnd_box_size=BND_BOX_SIZE\n",
    "    )\n",
    ")\n",
    "\n",
    "process_pipeline = RawImageToFeatures(\n",
    "    processors=[],\n",
    "    descriptors=[\n",
    "        HOGDescriptor(\n",
    "            orientations = 9,\n",
    "            cells_per_block = (2, 2),\n",
    "            pixels_per_cell = (4, 4),\n",
    "            multichannel = True,\n",
    "            visualize = True\n",
    "        ),\n",
    "        LBPDescriptor(\n",
    "            bins = 256,\n",
    "            range = (0, 256)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "sliding_window = SlidingWindow(\n",
    "    step_size=20,\n",
    "    window_size=BND_BOX_SIZE\n",
    ")"
   ]
  },
  {
   "source": [
    "#### treshold = 0.9; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "Process ForkPoolWorker-4:\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 80, in process\n",
      "    img_lbp[i, j] = self._lbp_calculated_pixel(img_gray, i, j)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 45, in process\n",
      "    fd, hog_image = hog(\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 109, in _lbp_calculated_pixel\n",
      "    val_ar.append(self._get_pixel(img, center, x + 1, y + 1))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 80, in process\n",
      "    img_lbp[i, j] = self._lbp_calculated_pixel(img_gray, i, j)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 80, in process\n",
      "    img_lbp[i, j] = self._lbp_calculated_pixel(img_gray, i, j)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 45, in process\n",
      "    fd, hog_image = hog(\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 94, in _get_pixel\n",
      "    if img[x][y] >= center:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/skimage/feature/_hog.py\", line 255, in hog\n",
      "    hog_image[rr, cc] += orientation_histogram[r, c, o]\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 103, in _lbp_calculated_pixel\n",
      "    center = img[x][y]\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 94, in _get_pixel\n",
      "    if img[x][y] >= center:\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 105, in _lbp_calculated_pixel\n",
      "    val_ar.append(self._get_pixel(img, center, x-1, y-1))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 199, in _classify_image_for_parallel\n",
      "    features = self.process_pipeline.process(cropped_image)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/skimage/feature/_hog.py\", line 255, in hog\n",
      "    hog_image[rr, cc] += orientation_histogram[r, c, o]\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/pipelines.py\", line 49, in process\n",
      "    (features, descriptor.process(image)[0])\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 80, in process\n",
      "    img_lbp[i, j] = self._lbp_calculated_pixel(img_gray, i, j)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\", line 200, in _classify_image_for_parallel\n",
      "    prediction = self.classifier.predict(features.reshape(1, -1))[0]\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/features/descriptors.py\", line 45, in process\n",
      "    fd, hog_image = hog(\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/skimage/feature/_hog.py\", line 255, in hog\n",
      "    hog_image[rr, cc] += orientation_histogram[r, c, o]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/classifiers.py\", line 36, in predict\n",
      "    probes = self.model.predict_proba(x)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 119, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/sklearn/pipeline.py\", line 464, in predict_proba\n",
      "    return self.steps[-1][-1].predict_proba(Xt)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 667, in _predict_proba\n",
      "    return pred_proba(X)\n",
      "  File \"/home/kornel/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 711, in _dense_predict_proba\n",
      "    pprob = libsvm.predict_proba(\n",
      "KeyboardInterrupt\n",
      "  0%|          | 0/5 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b221120c036d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m true_positives, false_positives, false_negatives, processed_images = validate_model(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdataset_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_folder_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../../data/raw/orto/val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/evaluation.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(dataset_loader, input_folder_filepath, images_files_types, annotations_files_types, detector, output_folder_filepath, workers, iou_threshold)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         processed_images.append(\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image, workers, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbnd_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbnd_box\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbnd_boxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AOiW/cv_project/venv_cv/lib/python3.8/site-packages/src-0.1.0-py3.8.egg/src/models/detectors.py\u001b[0m in \u001b[0;36m_detect\u001b[0;34m(self, image, workers)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 results = p.map(\n\u001b[0m\u001b[1;32m    171\u001b[0m                     partial(\n\u001b[1;32m    172\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify_image_for_parallel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.9,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t9nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "source": [
    "#### treshold = 0.95; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No file ../../../data/raw/vehicules/val/00001185.txt\n",
      "No file ../../../data/raw/vehicules/val/00001143.txt\n",
      "No file ../../../data/raw/vehicules/val/00001248.txt\n",
      "No file ../../../data/raw/vehicules/val/00001145.txt\n",
      "No file ../../../data/raw/vehicules/val/00001244.txt\n",
      "  2%|▏         | 1/66 [00:33<36:41, 33.87s/it]1\n",
      "  3%|▎         | 2/66 [01:04<35:13, 33.02s/it]7\n",
      "  5%|▍         | 3/66 [01:35<34:02, 32.42s/it]3\n",
      "  6%|▌         | 4/66 [02:09<33:44, 32.66s/it]3\n",
      "  8%|▊         | 5/66 [02:40<32:52, 32.33s/it]3\n",
      "  9%|▉         | 6/66 [03:12<32:03, 32.06s/it]7\n",
      " 11%|█         | 7/66 [03:43<31:15, 31.79s/it]3\n",
      " 12%|█▏        | 8/66 [04:14<30:40, 31.73s/it]2\n",
      " 14%|█▎        | 9/66 [04:46<30:07, 31.70s/it]5\n",
      " 15%|█▌        | 10/66 [05:18<29:42, 31.83s/it]1\n",
      " 17%|█▋        | 11/66 [05:50<29:07, 31.78s/it]4\n",
      " 18%|█▊        | 12/66 [06:21<28:32, 31.72s/it]0\n",
      " 20%|█▉        | 13/66 [06:53<27:55, 31.62s/it]4\n",
      " 21%|██        | 14/66 [07:24<27:22, 31.59s/it]1\n",
      " 23%|██▎       | 15/66 [07:56<26:50, 31.59s/it]2\n",
      " 24%|██▍       | 16/66 [08:27<26:17, 31.55s/it]1\n",
      " 26%|██▌       | 17/66 [08:59<25:42, 31.48s/it]2\n",
      " 27%|██▋       | 18/66 [09:30<25:13, 31.53s/it]3\n",
      " 29%|██▉       | 19/66 [10:02<24:46, 31.64s/it]16\n",
      " 30%|███       | 20/66 [10:34<24:12, 31.57s/it]1\n",
      " 32%|███▏      | 21/66 [11:05<23:44, 31.65s/it]2\n",
      " 33%|███▎      | 22/66 [11:37<23:14, 31.69s/it]1\n",
      " 35%|███▍      | 23/66 [12:09<22:40, 31.65s/it]0\n",
      " 36%|███▋      | 24/66 [12:43<22:38, 32.34s/it]4\n",
      " 38%|███▊      | 25/66 [13:16<22:17, 32.63s/it]2\n",
      " 39%|███▉      | 26/66 [13:47<21:30, 32.25s/it]2\n",
      " 41%|████      | 27/66 [14:19<20:47, 31.98s/it]3\n",
      " 42%|████▏     | 28/66 [14:51<20:16, 32.02s/it]3\n",
      " 44%|████▍     | 29/66 [15:22<19:37, 31.82s/it]0\n",
      " 45%|████▌     | 30/66 [15:54<19:08, 31.89s/it]9\n",
      " 47%|████▋     | 31/66 [16:27<18:43, 32.11s/it]2\n",
      " 48%|████▊     | 32/66 [17:00<18:23, 32.45s/it]0\n",
      " 50%|█████     | 33/66 [17:34<18:03, 32.84s/it]0\n",
      " 52%|█████▏    | 34/66 [18:05<17:10, 32.20s/it]2\n",
      " 53%|█████▎    | 35/66 [18:35<16:21, 31.66s/it]2\n",
      " 55%|█████▍    | 36/66 [19:05<15:38, 31.27s/it]1\n",
      " 56%|█████▌    | 37/66 [19:36<15:02, 31.11s/it]7\n",
      " 58%|█████▊    | 38/66 [20:09<14:49, 31.78s/it]4\n",
      " 59%|█████▉    | 39/66 [20:42<14:24, 32.04s/it]0\n",
      " 61%|██████    | 40/66 [21:14<13:48, 31.88s/it]2\n",
      " 62%|██████▏   | 41/66 [21:45<13:15, 31.82s/it]0\n",
      " 64%|██████▎   | 42/66 [22:17<12:41, 31.73s/it]2\n",
      " 65%|██████▌   | 43/66 [22:49<12:10, 31.76s/it]3\n",
      " 67%|██████▋   | 44/66 [23:20<11:36, 31.67s/it]0\n",
      " 68%|██████▊   | 45/66 [23:52<11:04, 31.65s/it]5\n",
      " 70%|██████▉   | 46/66 [24:23<10:33, 31.66s/it]1\n",
      " 71%|███████   | 47/66 [24:55<10:01, 31.64s/it]2\n",
      " 73%|███████▎  | 48/66 [25:26<09:28, 31.58s/it]1\n",
      " 74%|███████▍  | 49/66 [25:58<08:56, 31.55s/it]0\n",
      " 76%|███████▌  | 50/66 [26:30<08:25, 31.60s/it]12\n",
      " 77%|███████▋  | 51/66 [27:01<07:54, 31.64s/it]6\n",
      " 79%|███████▉  | 52/66 [27:33<07:22, 31.61s/it]5\n",
      " 80%|████████  | 53/66 [28:07<07:01, 32.39s/it]5\n",
      " 82%|████████▏ | 54/66 [28:39<06:26, 32.22s/it]2\n",
      " 83%|████████▎ | 55/66 [29:11<05:52, 32.05s/it]2\n",
      " 85%|████████▍ | 56/66 [29:43<05:21, 32.13s/it]3\n",
      " 86%|████████▋ | 57/66 [30:15<04:48, 32.03s/it]0\n",
      " 88%|████████▊ | 58/66 [30:46<04:15, 31.89s/it]4\n",
      " 89%|████████▉ | 59/66 [31:18<03:43, 31.87s/it]3\n",
      " 91%|█████████ | 60/66 [31:49<03:10, 31.73s/it]0\n",
      " 92%|█████████▏| 61/66 [32:21<02:38, 31.73s/it]2\n",
      " 94%|█████████▍| 62/66 [32:53<02:06, 31.66s/it]0\n",
      " 95%|█████████▌| 63/66 [33:24<01:34, 31.65s/it]2\n",
      " 97%|█████████▋| 64/66 [33:56<01:03, 31.63s/it]3\n",
      " 98%|█████████▊| 65/66 [34:28<00:31, 31.65s/it]1\n",
      "100%|██████████| 66/66 [35:00<00:00, 31.82s/it]0\n",
      "\n",
      "\n",
      "Precision: 0.193\n",
      "Recall: 0.365\n",
      "F1Score: 0.252\n"
     ]
    }
   ],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.95,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t95nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "source": [
    "treshold = 0.98; nms_overlap=0.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_detector = SliderProbDetector(\n",
    "    sliding_window=sliding_window,\n",
    "    process_pipeline=process_pipeline,\n",
    "    classifier=ProbSVMModelWrapper(model),\n",
    "    treshold=0.98,\n",
    "    nms_overlap=0.4\n",
    ")\n",
    "\n",
    "true_positives, false_positives, false_negatives, processed_images = validate_model(\n",
    "    dataset_loader=dataset_loader,\n",
    "    input_folder_filepath='../../../data/raw/orto/val',\n",
    "    output_folder_filepath='../../processed_images/svm/orto/t98nms4',\n",
    "    images_files_types=('png',),\n",
    "    annotations_files_types=('json',),\n",
    "    detector=slider_detector,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Precision:',  round(precision(true_positives, false_positives), 3))\n",
    "print('Recall:',  round(recall(true_positives, false_negatives), 3))\n",
    "print('F1Score:', round(f1_score(true_positives, false_positives, false_negatives), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}